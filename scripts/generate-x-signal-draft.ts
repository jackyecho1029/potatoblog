import * as dotenv from 'dotenv';
import * as path from 'path';
import * as fs from 'fs';
import * as crypto from 'crypto';
import Parser from 'rss-parser';

// Load environment variables
dotenv.config({ path: path.join(process.cwd(), '.env.local') });

const RSSHUB_BASE_URL = 'http://localhost:1200';
const SOURCES_CONFIG_PATH = path.join(process.cwd(), 'config/x-sources-categorized.json');
const POSTS_DIR = path.join(process.cwd(), 'posts/x-signals');

// API Configuration
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const GLM_API_KEY = process.env.GLM_API_KEY;
const TWITTER_BEARER_TOKEN = process.env.TWITTER_BEARER_TOKEN;
const GLM_API_URL = 'https://open.bigmodel.cn/api/paas/v4/chat/completions';

const parser = new Parser();

// â”€â”€â”€ Type Definitions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

interface TweetItem {
    author: string;
    content: string;
    link: string;
    pubDate: string;
    fingerprint: string; // content hash for dedup
}

interface CategoryConfig {
    description: string;
    accounts: string[];
}

interface SourcesConfig {
    categories: Record<string, CategoryConfig>;
}

// â”€â”€â”€ Deduplication â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function getContentFingerprint(content: string): string {
    return crypto.createHash('md5').update(content.slice(0, 100).toLowerCase().trim()).digest('hex');
}

function getExistingDedupeSet(): Set<string> {
    const existing = new Set<string>();
    if (!fs.existsSync(POSTS_DIR)) return existing;

    const files = fs.readdirSync(POSTS_DIR)
        .filter(f => f.endsWith('.md'))
        .sort().reverse()
        .slice(0, 7);

    for (const file of files) {
        const content = fs.readFileSync(path.join(POSTS_DIR, file), 'utf-8');
        // Collect tweet links
        const links = content.match(/https?:\/\/(x\.com|twitter\.com)\/[a-zA-Z0-9_]+\/status\/\d+/g);
        if (links) links.forEach(l => existing.add(l));
        // Collect content fingerprints stored in comments
        const fps = content.match(/<!--fp:([a-f0-9]{32})-->/g);
        if (fps) fps.forEach(fp => existing.add(fp.replace(/<!--fp:|-->/g, '')));
    }
    return existing;
}

// â”€â”€â”€ Source Loading â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function loadCategorizedSources(): SourcesConfig {
    if (!fs.existsSync(SOURCES_CONFIG_PATH)) {
        console.error(`Config not found: ${SOURCES_CONFIG_PATH}`);
        process.exit(1);
    }
    return JSON.parse(fs.readFileSync(SOURCES_CONFIG_PATH, 'utf-8'));
}

// â”€â”€â”€ Fetching â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Twitter API v2 user ID cache to avoid repeated lookups
const userIdCache: Record<string, string> = {};

async function fetchTweetsFromTwitterAPI(username: string): Promise<TweetItem[]> {
    if (!TWITTER_BEARER_TOKEN) return [];

    try {
        // Step 1: Resolve username to user ID (with cache)
        if (!userIdCache[username]) {
            const userRes = await fetch(
                `https://api.twitter.com/2/users/by/username/${username}?user.fields=id`,
                { headers: { Authorization: `Bearer ${TWITTER_BEARER_TOKEN}` } }
            );
            if (!userRes.ok) {
                console.log(`  âš  Twitter API: user lookup failed for @${username} (${userRes.status})`);
                return [];
            }
            const userData = await userRes.json() as any;
            if (!userData.data?.id) return [];
            userIdCache[username] = userData.data.id;
        }

        const userId = userIdCache[username];

        // Step 2: Fetch recent tweets (last 3 days)
        const cutoff = new Date();
        cutoff.setDate(cutoff.getDate() - 3);
        const startTime = cutoff.toISOString();

        const tweetsRes = await fetch(
            `https://api.twitter.com/2/users/${userId}/tweets` +
            `?max_results=10&start_time=${startTime}` +
            `&tweet.fields=created_at,text` +
            `&exclude=retweets,replies`,
            { headers: { Authorization: `Bearer ${TWITTER_BEARER_TOKEN}` } }
        );

        if (!tweetsRes.ok) {
            console.log(`  âš  Twitter API: tweets fetch failed for @${username} (${tweetsRes.status})`);
            return [];
        }

        const tweetsData = await tweetsRes.json() as any;
        const items: TweetItem[] = (tweetsData.data || []).map((tweet: any) => {
            const content = tweet.text || '';
            return {
                author: username,
                content,
                link: `https://x.com/${username}/status/${tweet.id}`,
                pubDate: tweet.created_at || '',
                fingerprint: getContentFingerprint(content)
            };
        });

        return items;
    } catch (e) {
        console.log(`  âš  Twitter API error for @${username}: ${e}`);
        return [];
    }
}

async function fetchTweetsFromRSSHub(username: string): Promise<TweetItem[]> {
    const feedUrl = `${RSSHUB_BASE_URL}/twitter/user/${username}`;
    try {
        const feed = await parser.parseURL(feedUrl);
        const cutoff = new Date();
        cutoff.setDate(cutoff.getDate() - 3);

        return feed.items
            .filter(item => {
                const pubDate = item.pubDate ? new Date(item.pubDate) : new Date(0);
                return pubDate > cutoff;
            })
            .map(item => {
                const content = item.contentSnippet || item.content || '';
                return {
                    author: username,
                    content,
                    link: item.link || '',
                    pubDate: item.pubDate || '',
                    fingerprint: getContentFingerprint(content)
                };
            });
    } catch {
        return [];
    }
}

async function fetchTweetsFromSource(username: string): Promise<TweetItem[]> {
    // Tier 1: Twitter API v2 (direct, fastest)
    if (TWITTER_BEARER_TOKEN) {
        const tweets = await fetchTweetsFromTwitterAPI(username);
        if (tweets.length > 0) return tweets;
    }

    // Tier 2: RSSHub fallback
    return fetchTweetsFromRSSHub(username);
}

// â”€â”€â”€ AI Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function callAI(prompt: string): Promise<string> {
    if (GEMINI_API_KEY) {
        const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GEMINI_API_KEY}`;
        const res = await fetch(url, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] })
        });
        if (!res.ok) throw new Error(`Gemini error: ${res.status} - ${await res.text()}`);
        const data = await res.json() as any;
        return data.candidates[0].content.parts[0].text;
    } else if (GLM_API_KEY) {
        const res = await fetch(GLM_API_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${GLM_API_KEY}` },
            body: JSON.stringify({ model: 'glm-4-plus', messages: [{ role: 'user', content: prompt }], temperature: 0.7, max_tokens: 4096 })
        });
        if (!res.ok) throw new Error(`GLM error: ${res.status} - ${await res.text()}`);
        const data = await res.json() as { choices: { message: { content: string } }[] };
        return data.choices[0].message.content;
    } else {
        throw new Error('No API keys found in .env.local (GEMINI_API_KEY or GLM_API_KEY).');
    }
}

// â”€â”€â”€ Category Signal Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

interface CategorySignal {
    categoryName: string;
    selectedItems: SelectedItem[];
    summary: string;
    actions: string[];
}

interface SelectedItem {
    author: string;
    signal: string; // one-sentence Chinese distillation
    link: string;
    fingerprint: string;
}

async function generateCategorySignal(
    categoryName: string,
    description: string,
    tweets: TweetItem[],
    dateStr: string
): Promise<CategorySignal | null> {
    if (tweets.length === 0) {
        console.log(`  ğŸ“­ No tweets available for ${categoryName}, skipping.`);
        return null;
    }

    const tweetList = tweets.map((t, i) =>
        `[${i + 1}] @${t.author}\nå†…å®¹: ${t.content.slice(0, 300)}\né“¾æ¥: ${t.link}`
    ).join('\n---\n');

    const prompt = `ä½ æ˜¯"Potato"ï¼Œä¸€ä½é¡¶çº§ä¿¡æ¯ç­–å±•äººã€‚ä»Šå¤©æ˜¯ ${dateStr}ã€‚

ä½ è´Ÿè´£ç®¡ç†æ¿å—ã€Œ${categoryName}ã€ï¼ˆä¸»é¢˜ï¼š${description}ï¼‰ã€‚

ä»¥ä¸‹æ˜¯ä»è¯¥æ¿å—è®¢é˜…è´¦å·æŠ“å–åˆ°çš„æœ€æ–°å†…å®¹ï¼ˆæœ€å¤š${tweets.length}æ¡ï¼‰ï¼š

${tweetList}

## ä½ çš„ä»»åŠ¡

1. **å†…å®¹ç­›é€‰**ï¼šä»ä»¥ä¸Šå†…å®¹ä¸­ï¼Œé€‰å‡ºæœ€æœ‰ä»·å€¼ã€ä¿¡å·æœ€å¼ºçš„ 5~10 æ¡ã€‚å¦‚æœå†…å®¹å°‘äº5æ¡ï¼Œåˆ™å…¨éƒ¨é€‰å…¥ã€‚
2. **ä¿¡å·æç‚¼**ï¼šå¯¹æ¯æ¡é€‰ä¸­çš„å†…å®¹ï¼Œç”¨ä¸€å¥è¯ï¼ˆä¸­æ–‡ï¼Œâ‰¤60å­—ï¼‰æç‚¼æ ¸å¿ƒæ´è§ã€‚è¦çŠ€åˆ©æœ‰åŠ›ï¼Œä¸è¦åºŸè¯ã€‚
3. **æ¿å—æ€»ç»“**ï¼šä¸ºæœ¬æ¿å—å†™ä¸€æ®µä»Šæ—¥æ€»ç»“ï¼ˆ100-160å­—ï¼‰ï¼Œæ­ç¤ºè¿™äº›ä¿¡å·èƒŒåçš„å®è§‚è¶‹åŠ¿æˆ–å…±åŒä¸»é¢˜ã€‚
4. **è¡ŒåŠ¨å»ºè®®**ï¼šç»™å‡º 2~3 æ¡å…·ä½“å¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®ï¼Œä»¥"ä¸»æƒæ„å»ºè€…"çš„è§†è§’æ¥å†™ã€‚

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼Œä¸è¦å¤šä½™æ–‡å­—ï¼‰

ITEMS_START
åºå·|@è´¦å·|ä¿¡å·æç‚¼ï¼ˆä¸€å¥è¯ï¼‰|åŸæ–‡é“¾æ¥
1|@karpathy|...|https://...
2|@levelsio|...|https://...
ITEMS_END
SUMMARY_START
[æ¿å—æ€»ç»“å†…å®¹]
SUMMARY_END
ACTIONS_START
- [è¡ŒåŠ¨å»ºè®®1]
- [è¡ŒåŠ¨å»ºè®®2]
- [è¡ŒåŠ¨å»ºè®®3]
ACTIONS_END`;

    console.log(`  ğŸ¤– Generating signals for ${categoryName} (${tweets.length} tweets)...`);

    try {
        const raw = await callAI(prompt);
        return parseCategoryResponse(categoryName, tweets, raw);
    } catch (e) {
        console.error(`  âŒ AI generation failed for ${categoryName}:`, e);
        return null;
    }
}

function parseCategoryResponse(categoryName: string, sourceTweets: TweetItem[], raw: string): CategorySignal {
    // Parse ITEMS
    const itemsMatch = raw.match(/ITEMS_START\n([\s\S]*?)\nITEMS_END/);
    const selectedItems: SelectedItem[] = [];

    if (itemsMatch) {
        const lines = itemsMatch[1].trim().split('\n').filter(l => l.includes('|'));
        for (const line of lines) {
            const parts = line.split('|');
            if (parts.length >= 4) {
                const authorHandle = parts[1]?.trim().replace('@', '').toLowerCase();
                const signal = parts[2]?.trim();
                const link = parts[3]?.trim();

                // Find fingerprint from source tweets
                const sourceTweet = sourceTweets.find(t =>
                    t.author.toLowerCase() === authorHandle ||
                    t.link === link
                );

                selectedItems.push({
                    author: parts[1]?.trim(),
                    signal,
                    link,
                    fingerprint: sourceTweet?.fingerprint || getContentFingerprint(signal)
                });
            }
        }
    }

    // Parse SUMMARY
    const summaryMatch = raw.match(/SUMMARY_START\n([\s\S]*?)\nSUMMARY_END/);
    const summary = summaryMatch ? summaryMatch[1].trim() : 'æš‚æ— æ€»ç»“ã€‚';

    // Parse ACTIONS
    const actionsMatch = raw.match(/ACTIONS_START\n([\s\S]*?)\nACTIONS_END/);
    const actions = actionsMatch
        ? actionsMatch[1].trim().split('\n').map(a => a.replace(/^-\s*/, '').trim()).filter(Boolean)
        : [];

    return { categoryName, selectedItems, summary, actions };
}

// â”€â”€â”€ Markdown Rendering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function renderCategorySection(signal: CategorySignal): string {
    const itemRows = signal.selectedItems.map((item, i) =>
        `| ${i + 1} | ${item.author} | ${item.signal} <!--fp:${item.fingerprint}--> | [â†’ åŸæ–‡](${item.link}) |`
    ).join('\n');

    const actionList = signal.actions.map(a => `- ğŸ’¡ ${a}`).join('\n');

    return `## ${signal.categoryName}

| # | æ¥æº | ä»Šæ—¥ä¿¡å· | é“¾æ¥ |
|---|------|---------|------|
${itemRows}

> **æ¿å—æ€»ç»“** | ${signal.summary}

**âš¡ è¡ŒåŠ¨å»ºè®®**
${actionList}

`;
}

function buildFallbackContent(dateStr: string): string {
    return `---
title: "Daily X Signals: ${dateStr}"
date: "${dateStr}"
category: "X Signal"
tags: ["X", "AI", "è´¢å¯Œ", "è¥é”€", "æ™ºæ…§"]
---

> âš ï¸ **ä»Šæ—¥ä¿¡å·ï¼šRSSHub è¿æ¥å¼‚å¸¸ï¼Œæ— æ³•æŠ“å–å®æ—¶æ•°æ®ã€‚**
> å»ºè®®æ£€æŸ¥ RSSHub æœåŠ¡çŠ¶æ€ï¼ˆ\`http://localhost:1200\`ï¼‰åé‡æ–°è¿è¡Œã€‚

---
*Curated by Potato | Powered by Antigravity*
`;
}

// â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function main() {
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('  ğŸ›°  X Signal Categorized Briefing');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    const config = loadCategorizedSources();
    const dedupeSet = getExistingDedupeSet();
    console.log(`ğŸ“š Dedup set loaded: ${dedupeSet.size} known items\n`);

    // â”€â”€ Date Setup â”€â”€
    const today = new Date();
    const offset = today.getTimezoneOffset() * 60000;
    const localDate = new Date(today.getTime() - offset);
    const dateStr = localDate.toISOString().split('T')[0];
    const filename = `${dateStr}-daily-signals.md`;
    const filepath = path.join(POSTS_DIR, filename);

    // â”€â”€ Fetch all tweets per category â”€â”€
    const categoryTweets: Record<string, TweetItem[]> = {};
    let totalFetched = 0;

    for (const [categoryName, categoryConfig] of Object.entries(config.categories)) {
        console.log(`\nğŸ“¡ Fetching [${categoryName}]...`);
        let catTweets: TweetItem[] = [];

        for (const username of categoryConfig.accounts) {
            const tweets = await fetchTweetsFromSource(username);
            const fresh = tweets.filter(t => !dedupeSet.has(t.link) && !dedupeSet.has(t.fingerprint));
            catTweets = catTweets.concat(fresh);
            totalFetched += fresh.length;
        }

        // Sort newest-first, limit to 30 for prompt efficiency
        catTweets.sort((a, b) => new Date(b.pubDate).getTime() - new Date(a.pubDate).getTime());
        categoryTweets[categoryName] = catTweets.slice(0, 30);
        console.log(`  âœ… ${catTweets.length} fresh tweets`);
    }

    console.log(`\nğŸ“Š Total fresh tweets: ${totalFetched}`);

    // â”€â”€ Handle no data â”€â”€
    if (totalFetched === 0) {
        console.log('\nâš ï¸  No live data available. RSSHub may be offline.');
        console.log('ğŸ’¡ Tip: Start RSSHub with `npx rsshub` or check http://localhost:1200');

        if (!fs.existsSync(filepath)) {
            if (!fs.existsSync(POSTS_DIR)) fs.mkdirSync(POSTS_DIR, { recursive: true });
            fs.writeFileSync(filepath, buildFallbackContent(dateStr));
            console.log(`ğŸ“ Created fallback file: ${filename}`);
        }
        return;
    }

    // â”€â”€ Generate category signals â”€â”€
    const categorySignals: CategorySignal[] = [];

    for (const [categoryName, tweets] of Object.entries(categoryTweets)) {
        const description = config.categories[categoryName].description;
        const signal = await generateCategorySignal(categoryName, description, tweets, dateStr);
        if (signal && signal.selectedItems.length > 0) {
            categorySignals.push(signal);
            // Add selected items to dedup set for future runs
            signal.selectedItems.forEach(item => {
                dedupeSet.add(item.link);
                dedupeSet.add(item.fingerprint);
            });
        }
    }

    if (categorySignals.length === 0) {
        console.log('âŒ No category signals generated. Check AI API keys.');
        return;
    }

    // â”€â”€ Build the final Markdown â”€â”€
    const totalItems = categorySignals.reduce((sum, s) => sum + s.selectedItems.length, 0);

    const categorySections = categorySignals.map(renderCategorySection).join('---\n\n');

    const fullContent = `---
title: "X Signal Daily Briefing: ${dateStr}"
date: "${dateStr}"
category: "X Signal"
tags: ["X", "AI", "è´¢å¯Œ", "è¥é”€", "æ™ºæ…§", "æ—¥æŠ¥"]
---

> **Potato's Daily Briefing** Â· ${dateStr} Â· ä»Šæ—¥ç²¾é€‰ **${totalItems}** æ¡ä¿¡å·ï¼Œè¦†ç›– **${categorySignals.length}** ä¸ªæ¿å—

---

${categorySections}---

*Curated by Potato Â· Powered by Antigravity Â· ${new Date().toLocaleTimeString('zh-CN', { hour12: false, hour: '2-digit', minute: '2-digit' })}*
`;

    if (!fs.existsSync(POSTS_DIR)) fs.mkdirSync(POSTS_DIR, { recursive: true });

    if (fs.existsSync(filepath)) {
        // Append as a new update block
        const existing = fs.readFileSync(filepath, 'utf-8');
        const updateBlock = `\n\n## ğŸ”„ æ›´æ–° ${localDate.getHours()}:${localDate.getMinutes().toString().padStart(2, '0')}\n\n${categorySections}`;
        fs.writeFileSync(filepath, existing + updateBlock);
        console.log(`\nâœ… Appended update to: ${filename}`);
    } else {
        fs.writeFileSync(filepath, fullContent);
        console.log(`\nâœ… Created new briefing: ${filename}`);
    }

    console.log(`\nğŸ“‹ Summary:`);
    categorySignals.forEach(s => console.log(`  ${s.categoryName}: ${s.selectedItems.length} signals`));
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
}

main().catch(console.error);
